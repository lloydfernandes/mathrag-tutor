# ğŸ“š Local RAG Math Tutor (Offline Chatbot)

A fully offline, local chatbot that answers math questions by retrieving relevant examples from a custom knowledge base using **RAG (Retrieval-Augmented Generation)** and a **locally running LLM via Ollama**.

---

## ğŸš€ Features

- ğŸ§  **RAG-powered**: Retrieves real math examples to ground its answers.
- ğŸ§© **Uses local LLMs**: No internet, no OpenAI API needed.
- ğŸ§¾ **Your own knowledge base**: Add math problems in `.txt` or `.jsonl` files.
- âš¡ï¸ **Fast + Private**: Everything runs locally using ChromaDB and Ollama.
- ğŸ’¬ **Streamlit interface**: Simple web app for interaction.
- ğŸ“Š **Progress tracking**: See your accuracy, topic breakdown, and export logs.
- ğŸ§  **LLM-based topic tagging**: Automatically classifies each question into a math topic.

---

## ğŸ“ Project Structure

```
mathrag/
â”œâ”€â”€ main.py                 # Streamlit app
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Files/folders to exclude from Git
â”œâ”€â”€ agents/                 # Core agents
â”‚   â”œâ”€â”€ explainer.py        # ExplainerAgent with RAG and topic classifier
â”‚   â”œâ”€â”€ grader.py           # GraderAgent for checking answers
â”‚   â”œâ”€â”€ supervisor.py       # Routes queries to agents
â”‚   â””â”€â”€ memory_agent.py     # Tracks and exports performance data
â”œâ”€â”€ practice/
â”‚   â”œâ”€â”€ practice.py         # PracticeAgent for question serving
â”‚   â””â”€â”€ session_tracker.py  # Tracks attempts per session
â”œâ”€â”€ data/
â”‚   â””â”€â”€ gsm8k/              # Math dataset (.jsonl or .txt)
â”œâ”€â”€ chroma_math_db*/        # Auto-generated vector DB (ignored by Git)
```

---

## ğŸ§  How It Works

1. Loads math problem files from `data/gsm8k/`
2. Splits and embeds them using `sentence-transformers`
3. Stores embeddings in a local Chroma vector store
4. Uses retrieval to fetch similar examples for any user query
5. Feeds query + context into a local LLM like `mistral` via **Ollama**
6. Classifies topic using LLM for every practice question
7. Tracks and exports accuracy and performance stats

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone git@github.com:lloydfernandes/mathrag-tutor.git
cd mathrag-tutor
```

### 2. Set Up a Conda Environment

```bash
conda create -n mathrag python=3.10
conda activate mathrag
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install & Start Ollama

Download Ollama from [https://ollama.com](https://ollama.com)

Then run a local model:
```bash
ollama run mistral
# or
ollama run qwen:7b
```

### 5. Add Math Problems

Put your `.txt` or `train.jsonl` math problems in:
```
data/gsm8k/
```

**Example (`problem1.txt`)**
```
Question: Jane has 3 apples. She buys 4 more. How many apples does she have now?
Answer: 3 + 4 = 7. Jane has 7 apples.
```

**OR** use the official GSM8K dataset in `train.jsonl` format.

### 6. Run the App

```bash
streamlit run main.py
```

Open the app in your browser: `http://localhost:8501`

---

## ğŸ§ª Modes to Explore

- ğŸ§  **Explain**: Ask any math question and get a grounded answer
- ğŸ§ª **Practice**: Answer random or weak-topic questions
- ğŸ¯ **Grade**: Compare your answer to a correct one
- ğŸ“ˆ **Progress**: View accuracy and performance by topic
- ğŸ“ **Session Log**: Review every question and feedback

---

## ğŸ“¦ Dependencies

```
langchain
chromadb
sentence-transformers
transformers
torch
streamlit
```

Install all with:
```bash
pip install -r requirements.txt
```

---

## ğŸ§  Credits & Acknowledgments

- Built on top of [LangChain](https://github.com/langchain-ai/langchain)
- Uses [ChromaDB](https://github.com/chroma-core/chroma) for local vector search
- Powered by open-source LLMs (via [Ollama](https://ollama.com))
- Dataset based on [GSM8K](https://huggingface.co/datasets/gsm8k)

---

## ğŸ” License

MIT License â€” free to use, modify, and share!
